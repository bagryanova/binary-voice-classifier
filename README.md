# binary-voice-classifier

Классификатор мужских и женских голосов на базе [LibriTTS](https://openslr.org/60/). 
Был сделан в качестве тестового задания при отборе на НИР в ВШЭ СПб весной 2022.

## Как запустить
Я вела разработку в [Google Colab](https://colab.research.google.com). При запуске файлов там никаких дополнительных дейтсвий потребоваться не должно (все библиотеки и датасет загружаются в коде).

## Процесс работы и описание результатов

### Анализ данных
Первым делом я загрузила датасет, чтобы посмотреть на него глазами, и почитала информацию о нем. 
Первое, с чем я столкнулась – датасет был большой, так что я взяла его маленькую часть
`train-clean-100` (33236 записей) и работала с ней. В качестве тестовой выборки взяла `test-clean` (4837 записей).

В рабочем датасете присутствуют голоса 247 людей (с пометками мужчина или женщина). У каждой записи
есть много информации – аудио и текстовая интерпретация и дополнительная информация. 
Я решала задачу определения пола по звуковым данным, поэтому использовала их (`waveform`), а также дополнительную информацию,
которая помогала в работе (`sample_rate, speaker_id, gender from speaker id`).

Дополнительно я проверила качество данных (в файле с CNN):
* Все спикеры из тестового и тренировочного датасетов имели данные о поле
* В тестовом датасете не было спикеров из тренировочного датасета

### Выбор метода
Далее я провела небольшое исследование подходов к решению этой задачи.
Во всех статьях (например [здесь](https://iopscience.iop.org/article/10.1088/1757-899X/263/4/042083/pdf)) исследователи выделяли SVM как один из самых результативных методов, так что я решила начать с него. 
Для этого мне нужно было извлечь из данных признаки, в статьях часто упоминались MFCCs, я решила начать с них.

Также некоторые писали про результативность нейронных сетей (например 
[здесь](https://ijrcar.com/Volume_7_Issue_11/v7i1101.pdf) и [здесь](https://towardsdatascience.com/voice-classification-with-neural-networks-ff90f94358ec)). Так что вторым подходом была CNN, все, что связанно с сетью я подсмотрела [здесь](https://pytorch.org/tutorials/intermediate/speech_command_classification_with_torchaudio_tutorial.html).

В качестве метрики я выбрала классическую `Accuracy`. В задаче нужно классифицировать данные на два класса равной важности ошибки, так что метрика хорошо подходит и как раз отражает количество правильных классификаций.

### Описание экспериментов
1. Сначала я провела эксперимент на датасете используя стандартный SVM с RBF ядром. И получила `accuracy = 0.878`. 
2. Далее я провела эксперимент используя SVM с линейным ядром (потому что подумала, что RBF может переобучаться).И получила `accuracy = 0.916`.
3. Провела эксперимент с CNN. После 6 эпох получила `accuracy = 0.974`

### Анализ результатов
Все три подхода показали достаточно хорошие результаты по метрике. 

В качестве дальнейших улучшений было бы интересно попробовать другие настройки параметров у моделей или нейросеть другой архитектуры, возможно, это дало бы лучший результат. Также чуть лучше поработать с данными – в SVM взять другие признаки вместо MFCCs, сделать с ними что-то более умное (я пока беру среднее по признаку). Потому что в статьях SVM показывал лучший результат.
И попробовать провести эксперимент на части датасета other. 
